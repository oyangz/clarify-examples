{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker MLOps Clarify Team Demo - Configuring Features to Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Contents\n",
    "\n",
    "1. [Overview](#Overview)\n",
    "1. [Prerequisites and Data](#Prerequisites-and-Data)\n",
    "    1. [Import libraries](#Import-libraries)\n",
    "    1. [Set configurations](#Set-configurations)\n",
    "    1. [Download data](#Download-data)\n",
    "    1. [Loading the data: Adult Dataset](#Loading-the-data:-Adult-Dataset) \n",
    "    1. [Data inspection](#Data-inspection) \n",
    "    1. [Encode and Upload the Dataset](#Encode-and-Upload-the-Dataset) \n",
    "1. [Train and Deploy XGBoost Model](#Train-XGBoost-Model)\n",
    "    1. [Train Model](#Train-Model)\n",
    "    1. [Create Model](#Create-Model)\n",
    "1. [Amazon SageMaker Clarify](#Amazon-SageMaker-Clarify)\n",
    "    1. [Set Configurations](#Set-Configurations)\n",
    "    1. [Get Started with a SageMaker Clarify Container](#Get-Started-with-a-SageMaker-Clarify-Container)\n",
    "    1. [Explaining Predictions](#Explaining-Predictions)\n",
    "        1. [Configure a SageMaker Clarify Processing Job Container's Input and Output Parameters ](#Configure-a-SageMaker-Clarify-Processing-Job-Container's-input-and-output-parameters)\n",
    "        1. [Configure Analysis Config](#Configure-analysis-config)\n",
    "        1. [Run SageMaker Clarify Processing Job](#Run-SageMaker-Clarify-Processing-job)\n",
    "        1. [Viewing the Explainability Report](#Viewing-the-Explainability-Report)\n",
    "        1. [Analysis of local explanations](#Analysis-of-local-explanations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Amazon SageMaker Clarify can help improve your machine learning models by explaining how these models make predictions. Specifically, Clarify uses the Kernel SHAP algorithm to explain the contribution that each model feature makes to the final prediction. \n",
    "\n",
    "By default, Clarify computes feature importance for every feature in the model input. This demo illustrate a new configuration we have for tabular SHAP explainability to select model feature columns for explainability calculations.\n",
    "\n",
    "### Customer - SageMaker AutoPilot\n",
    "\n",
    "* Autopilot has integrated Clarify's explainability analysis and report generation for the models they create.\n",
    "* With Autopilot, customers can select dataset features for model training. \n",
    "* Internally, Autopilot treats unselected features as model input before applying a column selection feature transform and training a downstream model only on the customer selected features.\n",
    "\n",
    "### Customer Requirement\n",
    "\n",
    "* To be able to exclude some features from explainability computations, while still sending them to the model.\n",
    "\n",
    "\n",
    "\n",
    "## In this demo, we will walk through:\n",
    "\n",
    "* Key terms and concepts needed to understand SageMaker Clarify \n",
    "* Analysis configuration for explainability and how to configure `features_to_explain`\n",
    "* The corresponding analysis output and report in SageMaker Studio.\n",
    "\n",
    "In doing so, we first trains a [SageMaker XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) model using the UCI adult dataset, then utilizes the [AWS SDK for Python](https://aws.amazon.com/sdk-for-python/) to launch SageMaker Clarify jobs to analyze an example dataset in CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import boto3\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sagemaker import get_execution_role, session\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize sagemaker session\n",
    "sagemaker_session = session.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-sagemaker-clarify-features-to-explain\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data\n",
    "Data Source: [https://archive.ics.uci.edu/ml/machine-learning-databases/adult/](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/)\n",
    "\n",
    "$^{[2]}$Dua Dheeru, and Efi Karra Taniskidou. \"[UCI Machine Learning Repository](http://archive.ics.uci.edu/ml)\". Irvine, CA: University of California, School of Information and Computer Science (2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Downloader\n",
    "\n",
    "adult_columns = [\n",
    "    \"Age\",\n",
    "    \"Workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"Education\",\n",
    "    \"Education-Num\",\n",
    "    \"Marital Status\",\n",
    "    \"Occupation\",\n",
    "    \"Relationship\",\n",
    "    \"Ethnic group\",\n",
    "    \"Sex\",\n",
    "    \"Capital Gain\",\n",
    "    \"Capital Loss\",\n",
    "    \"Hours per week\",\n",
    "    \"Country\",\n",
    "    \"Target\",\n",
    "]\n",
    "\n",
    "S3Downloader.download(\n",
    "    s3_uri=\"s3://{}/{}\".format(f\"sagemaker-example-files-prod-{region}\", \"datasets/tabular/uci_adult/adult.data\"),\n",
    "    local_path=\"./\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "S3Downloader.download(\n",
    "    s3_uri=\"s3://{}/{}\".format(f\"sagemaker-example-files-prod-{region}\", \"datasets/tabular/uci_adult/adult.test\"),\n",
    "    local_path=\"./\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading the data: Adult Dataset\n",
    "From the UCI repository of machine learning datasets, this database contains 14 features concerning demographic characteristics of 45,222 rows (32,561 for training and 12,661 for testing). The task is to predict whether a person has a yearly income that is more or less than $50,000.\n",
    "\n",
    "Here are the features and their possible values:\n",
    "\n",
    "1. **Age**: continuous.\n",
    "1. **Workclass**: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "1. **Fnlwgt**: continuous (the number of people the census takers believe that observation represents).\n",
    "1. **Education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "1. **Education-num**: continuous.\n",
    "1. **Marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "1. **Occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "1. **Relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "1. **Ethnic group**: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "1. **Sex**: Female, Male.\n",
    "    * **Note**: this data is extracted from the 1994 Census and enforces a binary option on Sex\n",
    "1. **Capital-gain**: continuous.\n",
    "1. **Capital-loss**: continuous.\n",
    "1. **Hours-per-week**: continuous.\n",
    "1. **Native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "Next, we specify our binary prediction task: \n",
    "\n",
    "15. **Target**: <=50,000, >$50,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>Education</th>\n",
       "      <th>Education-Num</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Ethnic group</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Capital Gain</th>\n",
       "      <th>Capital Loss</th>\n",
       "      <th>Hours per week</th>\n",
       "      <th>Country</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age         Workclass  fnlwgt  Education  Education-Num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       Marital Status         Occupation   Relationship Ethnic group     Sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family        White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband        White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family        White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband        Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife        Black  Female   \n",
       "\n",
       "   Capital Gain  Capital Loss  Hours per week        Country Target  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv(\n",
    "    \"adult.data\", names=adult_columns, sep=r\"\\s*,\\s*\", engine=\"python\", na_values=\"?\"\n",
    ").dropna()\n",
    "\n",
    "testing_data = pd.read_csv(\n",
    "    \"adult.test\", names=adult_columns, sep=r\"\\s*,\\s*\", engine=\"python\", na_values=\"?\", skiprows=1\n",
    ").dropna()\n",
    "\n",
    "training_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode and Upload the Dataset\n",
    "Here we encode the training and test data. Encoding input data is not necessary for SageMaker Clarify, but is necessary for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def number_encode_features(df):\n",
    "    result = df.copy()\n",
    "    encoders = {}\n",
    "    for column in result.columns:\n",
    "        if result.dtypes[column] == np.object:\n",
    "            encoders[column] = preprocessing.LabelEncoder()\n",
    "            result[column] = encoders[column].fit_transform(result[column].fillna(\"None\"))\n",
    "    return result, encoders\n",
    "\n",
    "\n",
    "training_data = pd.concat([training_data[\"Target\"], training_data.drop([\"Target\"], axis=1)], axis=1)\n",
    "training_data, _ = number_encode_features(training_data)\n",
    "training_data.to_csv(\"train_data.csv\", index=False, header=False)\n",
    "\n",
    "testing_data, _ = number_encode_features(testing_data)\n",
    "test_features = testing_data.drop([\"Target\"], axis=1)\n",
    "test_target = testing_data[\"Target\"]\n",
    "test_features.to_csv(\"test_features.csv\", index=False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note about our encoding: the \"Female\" Sex value has been encoded as 0 and \"Male\" as 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's upload the data to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_uri = S3Uploader.upload(\n",
    "    local_path=\"train_data.csv\",\n",
    "    desired_s3_uri=\"s3://{}/{}\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "train_input = TrainingInput(train_uri, content_type=\"csv\")\n",
    "test_uri = S3Uploader.upload(\n",
    "    local_path=\"test_features.csv\",\n",
    "    desired_s3_uri=\"s3://{}/{}\".format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost Model\n",
    "#### Train Model\n",
    "Since our focus is on understanding how to use SageMaker Clarify, we keep it simple by using a standard XGBoost model. For this section we will be using Amazon SageMaker Python SDK for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-06-15 06:51:15 Starting - Starting the training job...\n",
      "2023-06-15 06:51:32 Starting - Preparing the instances for training.........\n",
      "2023-06-15 06:52:23 Downloading - Downloading input data....\n",
      "2023-06-15 06:52:48 Training - Downloading the training image....\n",
      "2023-06-15 06:53:14 Training - Training image download completed. Training in progress......\n",
      "2023-06-15 06:53:44 Uploading - Uploading generated training model.\n",
      "2023-06-15 06:53:56 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "# This is references the AWS managed XGBoost container\n",
    "xgboost_image_uri = retrieve(region=region, framework=\"xgboost\", version=\"1.5-1\")\n",
    "\n",
    "xgb = Estimator(\n",
    "    xgboost_image_uri,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    disable_profiler=True,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=800,\n",
    ")\n",
    "\n",
    "xgb.fit({\"train\": train_input}, logs=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model\n",
    "Here we create the SageMaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEMO-clarify-xgboost-model'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"DEMO-clarify-xgboost-model\"\n",
    "model = xgb.create_model(name=model_name)\n",
    "container_def = model.prepare_container_def()\n",
    "sagemaker_session.create_model(model_name, role, container_def)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Clarify\n",
    "With your model set up, it's time to explore SageMaker Clarify. For a general overview of how SageMaker Clarify processing jobs work, refer to [the provided link](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-processing-job-configure-how-it-works.html). This section will demonstrate how to use the AWS SDK for Python (Boto3) to launch SageMaker Clarify processing jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialise SageMaker boto3 client\n",
    "sagemaker_client = boto3.Session().client(\"sagemaker\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Started with a SageMaker Clarify Container\n",
    "Amazon SageMaker provides prebuilt SageMaker Clarify container images that include the libraries and other dependencies needed to compute bias metrics and feature attributions for explainability. This image has been enabled to run SageMaker Clarify processing job in your account.\n",
    "\n",
    "The following code uses the SageMaker Python SDK API to easily retrieve the image URI. If you are unable to use the SageMaker Python SDK, you can find the image URI by referring to [the regional image URI page](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-processing-job-configure-container.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clarify Image URI: 306415355426.dkr.ecr.us-west-2.amazonaws.com/sagemaker-clarify-processing:1.0\n"
     ]
    }
   ],
   "source": [
    "clarify_image_uri = retrieve(region=region, framework=\"clarify\", version=\"1.0\")\n",
    "print(f\"Clarify Image URI: {clarify_image_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_processing_job(analysis_config_path, analysis_result_path):\n",
    "    processing_job_name = \"DEMO-clarify-job-{}\".format(datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\"))\n",
    "\n",
    "    response = sagemaker_client.create_processing_job(\n",
    "        ProcessingJobName=processing_job_name,\n",
    "        AppSpecification={\"ImageUri\": clarify_image_uri},\n",
    "        ProcessingInputs=[\n",
    "            {\n",
    "                \"InputName\": \"analysis_config\",\n",
    "                \"S3Input\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3InputMode\": \"File\",\n",
    "                    \"S3Uri\": analysis_config_path,\n",
    "                    \"LocalPath\": \"/opt/ml/processing/input/config\",\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"InputName\": \"dataset\",\n",
    "                \"S3Input\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3InputMode\": \"File\",\n",
    "                    \"S3Uri\": train_uri,\n",
    "                    \"LocalPath\": \"/opt/ml/processing/input/data\",\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        ProcessingOutputConfig={\n",
    "            \"Outputs\": [\n",
    "                {\n",
    "                    \"OutputName\": \"analysis_result\",\n",
    "                    \"S3Output\": {\n",
    "                        \"S3Uri\": analysis_result_path,\n",
    "                        \"LocalPath\": \"/opt/ml/processing/output\",\n",
    "                        \"S3UploadMode\": \"EndOfJob\",\n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        ProcessingResources={\n",
    "            \"ClusterConfig\": {\n",
    "                \"InstanceCount\": 1,\n",
    "                \"InstanceType\": \"ml.m5.xlarge\",\n",
    "                \"VolumeSizeInGB\": 30,\n",
    "            }\n",
    "        },\n",
    "        StoppingCondition={\n",
    "            \"MaxRuntimeInSeconds\": 3600,\n",
    "        },\n",
    "        RoleArn=role,\n",
    "    )\n",
    "\n",
    "    return processing_job_name\n",
    "\n",
    "# Wait for processing job to complete\n",
    "def wait_for_job(job_name):\n",
    "    while (\n",
    "        sagemaker_client.describe_processing_job(ProcessingJobName=job_name)[\"ProcessingJobStatus\"]\n",
    "        == \"InProgress\"\n",
    "    ):\n",
    "        print(\".\", end=\"\")\n",
    "        time.sleep(60)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "Here is a brief explanation of inputs used above, for detailed documentation check [CreateProcessingJob API reference](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateProcessingJob.html):\n",
    "\n",
    "* `AppSpecification`: Here we provide the region specific clarify image uri we fetched earlier\n",
    "* `ProcessingInputs`: Clarify job requires that you provide two ProcessingInput parameters.\n",
    "  * `InputName: analysis_config`: The analysis configuration JSON file for a SageMaker Clarify job must be specified as an Amazon S3 object with the InputName \"analysis_config\". We will be providing the example analysis_configs that we have provided with this notebook. \n",
    "  * `InputName: dataset`, dataset fetched earlier provided here as an Amazon S3 object.\n",
    "* `ProcessingOutputConfig`: The job also requires an output parameter, the output location as an Amazon S3 prefix with the OutputName \"analysis_result\". The S3UploadMode should be set to \"EndOfJob\", because the analysis results is generated at the end of the job. We will be providing here the `analysis_result_path` that we configured earlier.\n",
    "* `ProcessingResources` contains the ClusterConfig specifying the ML compute instance type we want to use and the count. SageMaker SHAP analysis is CPU-intensive, to speed up the analysis, use a better instance type, or add more instances to enable Spark parallelization. The SageMaker Clarify job doesnâ€™t use GPU.\n",
    "* `StoppingCondition`: Using a maximum limit of 60 min for example job run. You can set the MaxRuntimeInSeconds of a SageMaker Clarify job to up to 7 days (604800 seconds). If the job cannot be completed within this time limit, it will be force-stopped and no analysis results are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining Predictions\n",
    "SageMaker Clarify uses Kernel SHAP to explain the contribution that each input feature makes to the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure a SageMaker Clarify Processing Job Container's input and output parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainability_analysis_config_path = \"s3://{}/{}/explainability_analysis_config.json\".format(\n",
    "    bucket, prefix\n",
    ")\n",
    "explainability_analysis_result_path = \"s3://{}/{}/explainability_analysis_output\".format(\n",
    "    bucket, prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure analysis config\n",
    "For our example use case we will be using the following analysis config. \n",
    "\n",
    "Note that if you do not wish for all model features to be explained by Kernel SHAP, you can configure the `features_to_explain` parameter as a list of feature names or indices to specify the model features you would like explanations computed for as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"dataset_type\": \"text/csv\",\n",
      "    \"headers\": [\"Target\", \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital Status\", \"Occupation\", \"Relationship\", \"Ethnic group\", \"Sex\", \"Capital Gain\", \"Capital Loss\", \"Hours per week\", \"Country\"],\n",
      "    \"label\": \"Target\",\n",
      "    \"methods\": {\n",
      "        \"shap\": {\n",
      "            \"baseline\": [\n",
      "                [38, 2, 189794, 10, 10, 3, 6, 1, 4, 1, 1092, 88, 41, 36]\n",
      "            ],\n",
      "            \"num_samples\": 15,\n",
      "            \"agg_method\": \"mean_abs\",\n",
      "            \"use_logit\": false,\n",
      "            \"save_local_shap_values\": true,\n",
      "            \"features_to_explain\": [\"Age\", \"Education\", \"Occupation\"]\n",
      "        },\n",
      "        \"report\": {\n",
      "            \"name\": \"report\",\n",
      "            \"title\": \"Analysis Report\"\n",
      "        }\n",
      "    },\n",
      "    \"predictor\": {\n",
      "        \"model_name\": \"DEMO-clarify-xgboost-model\",\n",
      "        \"instance_type\": \"ml.m5.xlarge\",\n",
      "        \"initial_instance_count\": 1,\n",
      "        \"accept_type\": \"text/csv\",\n",
      "        \"content_type\": \"text/csv\"\n",
      "    }\n",
      "}"
     ]
    }
   ],
   "source": [
    "!echo\n",
    "!cat explainability_analysis_config.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`explainability_analysis_config.json` here contains configuration values for computing feature attribution using a SageMaker Clarify job:\n",
    "\n",
    "* `dataset_type` specify the format of your dataset, for this example as we are using csv dataset this will be `text/csv`\n",
    "* `headers` is the list of column names in the dataset\n",
    "* `label` specifies the ground truth label, in this example the \"Target\" column. The SageMaker Clarify job will drop the column and uses the remaining feature columns for explainability analysis.\n",
    "* `methods` is the list of methods and their parameters for the analyses and reports.\n",
    "  * `shap:` This section has the parameter for SHAP analysis. \n",
    "      * `baseline`: Kernel SHAP algorithm requires a baseline (also known as background dataset). If not provided, a baseline is calculated automatically by SageMaker Clarify using K-means or K-prototypes in the input dataset. Baseline dataset type shall be the same as `dataset_type`, and baseline samples shall only include features. By definition, `baseline` should either be a S3 URI to the baseline dataset file, or an in-place list of samples. In this case we chose the latter, and put the mean of the train dataset to the list. For more details on baseline selection please [refer this documentation](https://docs.aws.amazon.com/en_us/sagemaker/latest/dg/clarify-feature-attribute-shap-baselines.html).\n",
    "      * `features_to_explain`: a list of names or indices of model features you would like to be explained. If not provided, \n",
    "* `predictor` includes model configuration, this section is required if the analysis requires predictions from model\n",
    "  * `model_name`: name of the concerned model, using name of the xgboost model trained earlier, `DEMO-clarify-xgboost-model`\n",
    "  * `instance_type` and `initial_instance_count` specify your preferred instance type and instance count used to run your model on during SageMaker Clarify's processing. The testing dataset is small, so a single standard instance is good enough to run this example.\n",
    "  * `accept_type` denotes the endpoint response payload format, and `content_type` denotes the payload format of request to the endpoint. As per the example model we created above both of these will be `text/csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-678264136642/sagemaker/DEMO-sagemaker-clarify-features-to-explain/explainability_analysis_config.json'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the analysis_config to the concerned S3 path.\n",
    "S3Uploader.upload(\n",
    "    \"explainability_analysis_config.json\", \"s3://{}/{}\".format(bucket, prefix)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run SageMaker Clarify Processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\n"
     ]
    }
   ],
   "source": [
    "processing_job_name = create_processing_job(\n",
    "    explainability_analysis_config_path, explainability_analysis_result_path\n",
    ")\n",
    "wait_for_job(processing_job_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the Explainability Report\n",
    "Let's view the explainability report in Studio under the experiments tab. Note that explanations are only generated for features specified in `features_to_explain` in the analysis config.\n",
    "\n",
    "\n",
    "<img src=\"explainability_studio.png\">\n",
    "\n",
    "The Model Insights tab contains direct links to the report and model insights. \n",
    "\n",
    "The complete analysis report can also be accessed at the following S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-786499417150/sagemaker/DEMO-sagemaker-clarify-boto3/explainability_analysis_output'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainability_analysis_result_path\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
